  0%|          | 0/1688 [00:00<?, ?it/s]/home/scur2847/.local/lib/python3.11/site-packages/transformers/data/data_collator.py:656: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /gpfs/scratch1/nodespecific/gcn120/jenkins/build/PyTorch/2.1.2/foss-2023a-CUDA-12.1.1/pytorch-v2.1.2/torch/csrc/utils/tensor_new.cpp:261.)
  batch["labels"] = torch.tensor(batch["labels"], dtype=torch.int64)
                                                   
{'loss': 3.3622, 'grad_norm': 6.352710247039795, 'learning_rate': 3.921568627450981e-07, 'epoch': 0.0}
{'loss': 4.0533, 'grad_norm': 9.39472484588623, 'learning_rate': 7.843137254901962e-07, 'epoch': 0.0}
{'loss': 3.6748, 'grad_norm': 10.930510520935059, 'learning_rate': 1.1764705882352942e-06, 'epoch': 0.01}
{'loss': 3.7115, 'grad_norm': 7.1748857498168945, 'learning_rate': 1.5686274509803923e-06, 'epoch': 0.01}
{'loss': 3.8151, 'grad_norm': 8.438314437866211, 'learning_rate': 1.96078431372549e-06, 'epoch': 0.01}
{'loss': 4.3146, 'grad_norm': 23.423118591308594, 'learning_rate': 2.3529411764705885e-06, 'epoch': 0.01}
{'loss': 4.7656, 'grad_norm': 16.861202239990234, 'learning_rate': 2.7450980392156867e-06, 'epoch': 0.02}
{'loss': 3.7545, 'grad_norm': 7.898097991943359, 'learning_rate': 3.1372549019607846e-06, 'epoch': 0.02}
{'loss': 3.5696, 'grad_norm': 7.084636688232422, 'learning_rate': 3.529411764705883e-06, 'epoch': 0.02}
{'loss': 3.6854, 'grad_norm': 9.101821899414062, 'learning_rate': 3.92156862745098e-06, 'epoch': 0.02}
{'loss': 3.2913, 'grad_norm': 7.35336446762085, 'learning_rate': 4.313725490196079e-06, 'epoch': 0.03}
{'loss': 4.0752, 'grad_norm': 14.414944648742676, 'learning_rate': 4.705882352941177e-06, 'epoch': 0.03}
{'loss': 2.9667, 'grad_norm': 8.043523788452148, 'learning_rate': 5.098039215686274e-06, 'epoch': 0.03}
{'loss': 3.0484, 'grad_norm': 9.552709579467773, 'learning_rate': 5.4901960784313735e-06, 'epoch': 0.03}
{'loss': 2.9079, 'grad_norm': 8.415143013000488, 'learning_rate': 5.882352941176471e-06, 'epoch': 0.04}
{'loss': 2.4078, 'grad_norm': 5.760928630828857, 'learning_rate': 6.274509803921569e-06, 'epoch': 0.04}
{'loss': 2.7387, 'grad_norm': 17.23887825012207, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.04}
{'loss': 2.4703, 'grad_norm': 6.5148844718933105, 'learning_rate': 7.058823529411766e-06, 'epoch': 0.04}
{'loss': 2.3725, 'grad_norm': 8.048766136169434, 'learning_rate': 7.450980392156863e-06, 'epoch': 0.04}
{'loss': 2.1181, 'grad_norm': 7.294620513916016, 'learning_rate': 7.84313725490196e-06, 'epoch': 0.05}
{'loss': 2.3868, 'grad_norm': 10.544737815856934, 'learning_rate': 8.23529411764706e-06, 'epoch': 0.05}
{'loss': 1.9503, 'grad_norm': 9.02926254272461, 'learning_rate': 8.627450980392157e-06, 'epoch': 0.05}
{'loss': 2.1267, 'grad_norm': 18.09200668334961, 'learning_rate': 9.019607843137256e-06, 'epoch': 0.05}
{'loss': 1.7081, 'grad_norm': 13.625316619873047, 'learning_rate': 9.411764705882354e-06, 'epoch': 0.06}
{'loss': 1.5466, 'grad_norm': 5.707014083862305, 'learning_rate': 9.803921568627451e-06, 'epoch': 0.06}
{'loss': 1.3262, 'grad_norm': 3.0863473415374756, 'learning_rate': 1.0196078431372549e-05, 'epoch': 0.06}
{'loss': 1.4178, 'grad_norm': 4.376574993133545, 'learning_rate': 1.0588235294117648e-05, 'epoch': 0.06}
{'loss': 1.4083, 'grad_norm': 2.6950578689575195, 'learning_rate': 1.0980392156862747e-05, 'epoch': 0.07}
{'loss': 1.3297, 'grad_norm': 4.28451681137085, 'learning_rate': 1.1372549019607844e-05, 'epoch': 0.07}
{'loss': 1.1658, 'grad_norm': 3.8191096782684326, 'learning_rate': 1.1764705882352942e-05, 'epoch': 0.07}
{'loss': 1.1126, 'grad_norm': 3.110090970993042, 'learning_rate': 1.215686274509804e-05, 'epoch': 0.07}
{'loss': 1.3573, 'grad_norm': 3.445641279220581, 'learning_rate': 1.2549019607843138e-05, 'epoch': 0.08}
{'loss': 1.1916, 'grad_norm': 2.0610532760620117, 'learning_rate': 1.2941176470588238e-05, 'epoch': 0.08}
{'loss': 1.1096, 'grad_norm': 1.7165607213974, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.08}
{'loss': 1.1885, 'grad_norm': 2.836305618286133, 'learning_rate': 1.3725490196078432e-05, 'epoch': 0.08}
{'loss': 1.0493, 'grad_norm': 3.2486181259155273, 'learning_rate': 1.4117647058823532e-05, 'epoch': 0.09}
{'loss': 1.4694, 'grad_norm': 3.4616105556488037, 'learning_rate': 1.4509803921568629e-05, 'epoch': 0.09}
{'loss': 1.0552, 'grad_norm': 2.331435441970825, 'learning_rate': 1.4901960784313726e-05, 'epoch': 0.09}
{'loss': 1.2227, 'grad_norm': 1.8816732168197632, 'learning_rate': 1.5294117647058822e-05, 'epoch': 0.09}
{'loss': 1.4859, 'grad_norm': 2.5666534900665283, 'learning_rate': 1.568627450980392e-05, 'epoch': 0.09}
{'loss': 0.8749, 'grad_norm': 2.264300584793091, 'learning_rate': 1.607843137254902e-05, 'epoch': 0.1}
