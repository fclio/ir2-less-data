  0%|          | 0/844 [00:00<?, ?it/s][WARNING|logging.py:314] 2024-11-30 15:40:16,807 >> You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
                                                  
{'loss': 5.9153, 'learning_rate': 7.692307692307694e-07, 'epoch': 0.0}
{'loss': 5.9756, 'learning_rate': 1.5384615384615387e-06, 'epoch': 0.01}
{'loss': 5.4615, 'learning_rate': 2.307692307692308e-06, 'epoch': 0.01}
{'loss': 5.9353, 'learning_rate': 3.0769230769230774e-06, 'epoch': 0.02}
{'loss': 5.9105, 'learning_rate': 3.846153846153847e-06, 'epoch': 0.02}
{'loss': 5.4194, 'learning_rate': 4.615384615384616e-06, 'epoch': 0.03}
{'loss': 5.6458, 'learning_rate': 5.384615384615385e-06, 'epoch': 0.03}
{'loss': 4.5465, 'learning_rate': 6.153846153846155e-06, 'epoch': 0.04}
{'loss': 5.8917, 'learning_rate': 6.923076923076923e-06, 'epoch': 0.04}
{'loss': 3.9881, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.05}
{'loss': 4.8502, 'learning_rate': 8.461538461538462e-06, 'epoch': 0.05}
{'loss': 4.5869, 'learning_rate': 9.230769230769232e-06, 'epoch': 0.06}
{'loss': 5.0171, 'learning_rate': 1e-05, 'epoch': 0.06}
{'loss': 4.5625, 'learning_rate': 1.076923076923077e-05, 'epoch': 0.07}
{'loss': 4.6451, 'learning_rate': 1.1538461538461538e-05, 'epoch': 0.07}
{'loss': 4.3353, 'learning_rate': 1.230769230769231e-05, 'epoch': 0.08}
{'loss': 4.279, 'learning_rate': 1.3076923076923078e-05, 'epoch': 0.08}
{'loss': 4.563, 'learning_rate': 1.3846153846153847e-05, 'epoch': 0.09}
{'loss': 4.7931, 'learning_rate': 1.4615384615384615e-05, 'epoch': 0.09}
{'loss': 4.5299, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.09}
{'loss': 4.2231, 'learning_rate': 1.6153846153846154e-05, 'epoch': 0.1}
{'loss': 4.1672, 'learning_rate': 1.6923076923076924e-05, 'epoch': 0.1}
{'loss': 4.4241, 'learning_rate': 1.7692307692307694e-05, 'epoch': 0.11}
{'loss': 3.6485, 'learning_rate': 1.8461538461538465e-05, 'epoch': 0.11}
{'loss': 4.3963, 'learning_rate': 1.923076923076923e-05, 'epoch': 0.12}
{'loss': 4.6643, 'learning_rate': 2e-05, 'epoch': 0.12}
{'loss': 4.3204, 'learning_rate': 1.997555012224939e-05, 'epoch': 0.13}
{'loss': 4.2978, 'learning_rate': 1.995110024449878e-05, 'epoch': 0.13}
{'loss': 4.6909, 'learning_rate': 1.992665036674817e-05, 'epoch': 0.14}
{'loss': 4.2881, 'learning_rate': 1.9902200488997556e-05, 'epoch': 0.14}
{'loss': 4.4961, 'learning_rate': 1.9877750611246945e-05, 'epoch': 0.15}
{'loss': 4.1894, 'learning_rate': 1.9853300733496334e-05, 'epoch': 0.15}
{'loss': 3.7461, 'learning_rate': 1.9828850855745724e-05, 'epoch': 0.16}
{'loss': 4.0539, 'learning_rate': 1.980440097799511e-05, 'epoch': 0.16}
{'loss': 4.1208, 'learning_rate': 1.9779951100244502e-05, 'epoch': 0.17}
{'loss': 4.4578, 'learning_rate': 1.975550122249389e-05, 'epoch': 0.17}
{'loss': 4.0447, 'learning_rate': 1.9731051344743278e-05, 'epoch': 0.17}
{'loss': 4.0435, 'learning_rate': 1.9706601466992667e-05, 'epoch': 0.18}
{'loss': 4.0241, 'learning_rate': 1.9682151589242056e-05, 'epoch': 0.18}
{'loss': 3.7372, 'learning_rate': 1.9657701711491442e-05, 'epoch': 0.19}
{'loss': 3.9626, 'learning_rate': 1.9633251833740835e-05, 'epoch': 0.19}
{'loss': 3.3928, 'learning_rate': 1.960880195599022e-05, 'epoch': 0.2}
{'loss': 3.9112, 'learning_rate': 1.958435207823961e-05, 'epoch': 0.2}
{'loss': 3.9291, 'learning_rate': 1.9559902200489e-05, 'epoch': 0.21}
{'loss': 3.9865, 'learning_rate': 1.953545232273839e-05, 'epoch': 0.21}
{'loss': 4.1952, 'learning_rate': 1.9511002444987775e-05, 'epoch': 0.22}
{'loss': 3.0839, 'learning_rate': 1.9486552567237164e-05, 'epoch': 0.22}
{'loss': 3.4439, 'learning_rate': 1.9462102689486554e-05, 'epoch': 0.23}
{'loss': 3.504, 'learning_rate': 1.9437652811735943e-05, 'epoch': 0.23}
{'loss': 3.3439, 'learning_rate': 1.9413202933985333e-05, 'epoch': 0.24}
{'loss': 3.3772, 'learning_rate': 1.9388753056234722e-05, 'epoch': 0.24}
{'loss': 3.4297, 'learning_rate': 1.936430317848411e-05, 'epoch': 0.25}
{'loss': 3.1423, 'learning_rate': 1.9339853300733497e-05, 'epoch': 0.25}
{'loss': 3.0341, 'learning_rate': 1.9315403422982887e-05, 'epoch': 0.26}
{'loss': 2.8551, 'learning_rate': 1.9290953545232276e-05, 'epoch': 0.26}
{'loss': 2.3469, 'learning_rate': 1.9266503667481665e-05, 'epoch': 0.26}
{'loss': 2.2271, 'learning_rate': 1.924205378973105e-05, 'epoch': 0.27}
{'loss': 1.9851, 'learning_rate': 1.9217603911980444e-05, 'epoch': 0.27}
{'loss': 1.2275, 'learning_rate': 1.919315403422983e-05, 'epoch': 0.28}
{'loss': 1.5594, 'learning_rate': 1.916870415647922e-05, 'epoch': 0.28}
{'loss': 0.8849, 'learning_rate': 1.914425427872861e-05, 'epoch': 0.29}
{'loss': 0.8296, 'learning_rate': 1.9119804400977998e-05, 'epoch': 0.29}
{'loss': 0.8545, 'learning_rate': 1.9095354523227384e-05, 'epoch': 0.3}
{'loss': 0.7225, 'learning_rate': 1.9070904645476773e-05, 'epoch': 0.3}
{'loss': 0.5407, 'learning_rate': 1.9046454767726163e-05, 'epoch': 0.31}
{'loss': 0.5563, 'learning_rate': 1.9022004889975552e-05, 'epoch': 0.31}
{'loss': 0.5262, 'learning_rate': 1.899755501222494e-05, 'epoch': 0.32}
{'loss': 0.5092, 'learning_rate': 1.897310513447433e-05, 'epoch': 0.32}
{'loss': 0.5999, 'learning_rate': 1.8948655256723717e-05, 'epoch': 0.33}
{'loss': 0.579, 'learning_rate': 1.8924205378973106e-05, 'epoch': 0.33}
{'loss': 0.3912, 'learning_rate': 1.8899755501222495e-05, 'epoch': 0.34}
{'loss': 0.411, 'learning_rate': 1.8875305623471885e-05, 'epoch': 0.34}
{'loss': 0.4689, 'learning_rate': 1.8850855745721274e-05, 'epoch': 0.35}
{'loss': 0.4389, 'learning_rate': 1.882640586797066e-05, 'epoch': 0.35}
{'loss': 0.481, 'learning_rate': 1.880195599022005e-05, 'epoch': 0.35}
{'loss': 0.3555, 'learning_rate': 1.877750611246944e-05, 'epoch': 0.36}
{'loss': 0.3624, 'learning_rate': 1.8753056234718828e-05, 'epoch': 0.36}
{'loss': 0.3804, 'learning_rate': 1.8728606356968217e-05, 'epoch': 0.37}
{'loss': 0.4158, 'learning_rate': 1.8704156479217607e-05, 'epoch': 0.37}
{'loss': 0.329, 'learning_rate': 1.8679706601466993e-05, 'epoch': 0.38}
{'loss': 0.3986, 'learning_rate': 1.8655256723716385e-05, 'epoch': 0.38}
{'loss': 0.4125, 'learning_rate': 1.863080684596577e-05, 'epoch': 0.39}
{'loss': 0.3372, 'learning_rate': 1.860635696821516e-05, 'epoch': 0.39}
{'loss': 0.3414, 'learning_rate': 1.8581907090464547e-05, 'epoch': 0.4}
{'loss': 0.3715, 'learning_rate': 1.855745721271394e-05, 'epoch': 0.4}
{'loss': 0.2751, 'learning_rate': 1.8533007334963325e-05, 'epoch': 0.41}
{'loss': 0.4153, 'learning_rate': 1.8508557457212715e-05, 'epoch': 0.41}
{'loss': 0.2942, 'learning_rate': 1.8484107579462104e-05, 'epoch': 0.42}
{'loss': 0.3893, 'learning_rate': 1.8459657701711494e-05, 'epoch': 0.42}
{'loss': 0.3008, 'learning_rate': 1.843520782396088e-05, 'epoch': 0.43}
{'loss': 0.3649, 'learning_rate': 1.8410757946210272e-05, 'epoch': 0.43}
{'loss': 0.3136, 'learning_rate': 1.8386308068459658e-05, 'epoch': 0.44}
{'loss': 0.3723, 'learning_rate': 1.8361858190709048e-05, 'epoch': 0.44}
{'loss': 0.4238, 'learning_rate': 1.8337408312958437e-05, 'epoch': 0.44}
{'loss': 0.3373, 'learning_rate': 1.8312958435207826e-05, 'epoch': 0.45}
{'loss': 0.3296, 'learning_rate': 1.8288508557457216e-05, 'epoch': 0.45}
{'loss': 0.2803, 'learning_rate': 1.82640586797066e-05, 'epoch': 0.46}
{'loss': 0.334, 'learning_rate': 1.823960880195599e-05, 'epoch': 0.46}
{'loss': 0.3452, 'learning_rate': 1.821515892420538e-05, 'epoch': 0.47}
{'loss': 0.3583, 'learning_rate': 1.819070904645477e-05, 'epoch': 0.47}
{'loss': 0.3676, 'learning_rate': 1.816625916870416e-05, 'epoch': 0.48}
{'loss': 0.3218, 'learning_rate': 1.814180929095355e-05, 'epoch': 0.48}
{'loss': 0.356, 'learning_rate': 1.8117359413202934e-05, 'epoch': 0.49}
{'loss': 0.4515, 'learning_rate': 1.8092909535452324e-05, 'epoch': 0.49}
{'loss': 0.308, 'learning_rate': 1.8068459657701713e-05, 'epoch': 0.5}
{'loss': 0.3569, 'learning_rate': 1.8044009779951102e-05, 'epoch': 0.5}
{'loss': 0.2679, 'learning_rate': 1.8019559902200488e-05, 'epoch': 0.51}
{'loss': 0.3727, 'learning_rate': 1.799511002444988e-05, 'epoch': 0.51}
{'loss': 0.3461, 'learning_rate': 1.7970660146699267e-05, 'epoch': 0.52}
{'loss': 0.3731, 'learning_rate': 1.7946210268948656e-05, 'epoch': 0.52}
{'loss': 0.2804, 'learning_rate': 1.7921760391198046e-05, 'epoch': 0.52}
{'loss': 0.3697, 'learning_rate': 1.7897310513447435e-05, 'epoch': 0.53}
{'loss': 0.3356, 'learning_rate': 1.787286063569682e-05, 'epoch': 0.53}
{'loss': 0.3411, 'learning_rate': 1.784841075794621e-05, 'epoch': 0.54}
{'loss': 0.2818, 'learning_rate': 1.78239608801956e-05, 'epoch': 0.54}
{'loss': 0.3439, 'learning_rate': 1.779951100244499e-05, 'epoch': 0.55}
{'loss': 0.3742, 'learning_rate': 1.777506112469438e-05, 'epoch': 0.55}
{'loss': 0.2917, 'learning_rate': 1.7750611246943768e-05, 'epoch': 0.56}
{'loss': 0.3203, 'learning_rate': 1.7726161369193157e-05, 'epoch': 0.56}
{'loss': 0.4183, 'learning_rate': 1.7701711491442543e-05, 'epoch': 0.57}
{'loss': 0.3007, 'learning_rate': 1.7677261613691932e-05, 'epoch': 0.57}
{'loss': 0.4589, 'learning_rate': 1.7652811735941322e-05, 'epoch': 0.58}
{'loss': 0.2866, 'learning_rate': 1.762836185819071e-05, 'epoch': 0.58}
{'loss': 0.3175, 'learning_rate': 1.7603911980440097e-05, 'epoch': 0.59}
{'loss': 0.253, 'learning_rate': 1.757946210268949e-05, 'epoch': 0.59}
{'loss': 0.3473, 'learning_rate': 1.7555012224938876e-05, 'epoch': 0.6}
{'loss': 0.3676, 'learning_rate': 1.7530562347188265e-05, 'epoch': 0.6}
{'loss': 0.2942, 'learning_rate': 1.7506112469437655e-05, 'epoch': 0.61}
{'loss': 0.3504, 'learning_rate': 1.7481662591687044e-05, 'epoch': 0.61}
{'loss': 0.3163, 'learning_rate': 1.745721271393643e-05, 'epoch': 0.61}
{'loss': 0.2278, 'learning_rate': 1.7432762836185823e-05, 'epoch': 0.62}
{'loss': 0.2938, 'learning_rate': 1.740831295843521e-05, 'epoch': 0.62}
{'loss': 0.2785, 'learning_rate': 1.7383863080684598e-05, 'epoch': 0.63}
{'loss': 0.34, 'learning_rate': 1.7359413202933987e-05, 'epoch': 0.63}
{'loss': 0.3958, 'learning_rate': 1.7334963325183377e-05, 'epoch': 0.64}
{'loss': 0.333, 'learning_rate': 1.7310513447432763e-05, 'epoch': 0.64}
{'loss': 0.4159, 'learning_rate': 1.7286063569682152e-05, 'epoch': 0.65}
{'loss': 0.4091, 'learning_rate': 1.726161369193154e-05, 'epoch': 0.65}
{'loss': 0.3584, 'learning_rate': 1.723716381418093e-05, 'epoch': 0.66}
{'loss': 0.2672, 'learning_rate': 1.721271393643032e-05, 'epoch': 0.66}
{'loss': 0.2571, 'learning_rate': 1.718826405867971e-05, 'epoch': 0.67}
{'loss': 0.3282, 'learning_rate': 1.71638141809291e-05, 'epoch': 0.67}
{'loss': 0.3536, 'learning_rate': 1.7139364303178485e-05, 'epoch': 0.68}
{'loss': 0.2663, 'learning_rate': 1.7114914425427874e-05, 'epoch': 0.68}
{'loss': 0.3192, 'learning_rate': 1.7090464547677263e-05, 'epoch': 0.69}
{'loss': 0.2311, 'learning_rate': 1.7066014669926653e-05, 'epoch': 0.69}
{'loss': 0.4279, 'learning_rate': 1.704156479217604e-05, 'epoch': 0.7}
{'loss': 0.2862, 'learning_rate': 1.701711491442543e-05, 'epoch': 0.7}
{'loss': 0.3422, 'learning_rate': 1.6992665036674817e-05, 'epoch': 0.7}
{'loss': 0.2884, 'learning_rate': 1.6968215158924207e-05, 'epoch': 0.71}
{'loss': 0.3331, 'learning_rate': 1.6943765281173596e-05, 'epoch': 0.71}
{'loss': 0.2897, 'learning_rate': 1.6919315403422985e-05, 'epoch': 0.72}
{'loss': 0.2352, 'learning_rate': 1.689486552567237e-05, 'epoch': 0.72}
{'loss': 0.3625, 'learning_rate': 1.687041564792176e-05, 'epoch': 0.73}
{'loss': 0.308, 'learning_rate': 1.684596577017115e-05, 'epoch': 0.73}
{'loss': 0.4141, 'learning_rate': 1.682151589242054e-05, 'epoch': 0.74}
{'loss': 0.2598, 'learning_rate': 1.679706601466993e-05, 'epoch': 0.74}
{'loss': 0.2812, 'learning_rate': 1.6772616136919318e-05, 'epoch': 0.75}
{'loss': 0.292, 'learning_rate': 1.6748166259168704e-05, 'epoch': 0.75}
{'loss': 0.3676, 'learning_rate': 1.6723716381418093e-05, 'epoch': 0.76}
{'loss': 0.3112, 'learning_rate': 1.6699266503667483e-05, 'epoch': 0.76}
{'loss': 0.2551, 'learning_rate': 1.6674816625916872e-05, 'epoch': 0.77}
{'loss': 0.2516, 'learning_rate': 1.665036674816626e-05, 'epoch': 0.77}
{'loss': 0.29, 'learning_rate': 1.662591687041565e-05, 'epoch': 0.78}
{'loss': 0.2692, 'learning_rate': 1.6601466992665037e-05, 'epoch': 0.78}
{'loss': 0.3934, 'learning_rate': 1.6577017114914426e-05, 'epoch': 0.78}
{'loss': 0.3186, 'learning_rate': 1.6552567237163816e-05, 'epoch': 0.79}
{'loss': 0.2959, 'learning_rate': 1.6528117359413205e-05, 'epoch': 0.79}
{'loss': 0.2336, 'learning_rate': 1.6503667481662594e-05, 'epoch': 0.8}
{'loss': 0.2747, 'learning_rate': 1.647921760391198e-05, 'epoch': 0.8}
{'loss': 0.305, 'learning_rate': 1.6454767726161373e-05, 'epoch': 0.81}
{'loss': 0.3091, 'learning_rate': 1.643031784841076e-05, 'epoch': 0.81}
{'loss': 0.2765, 'learning_rate': 1.6405867970660148e-05, 'epoch': 0.82}
{'loss': 0.3659, 'learning_rate': 1.6381418092909538e-05, 'epoch': 0.82}
{'loss': 0.266, 'learning_rate': 1.6356968215158927e-05, 'epoch': 0.83}
{'loss': 0.2507, 'learning_rate': 1.6332518337408313e-05, 'epoch': 0.83}
{'loss': 0.1831, 'learning_rate': 1.6308068459657702e-05, 'epoch': 0.84}
{'loss': 0.3946, 'learning_rate': 1.628361858190709e-05, 'epoch': 0.84}
{'loss': 0.1696, 'learning_rate': 1.625916870415648e-05, 'epoch': 0.85}
{'loss': 0.27, 'learning_rate': 1.6234718826405867e-05, 'epoch': 0.85}
{'loss': 0.3273, 'learning_rate': 1.621026894865526e-05, 'epoch': 0.86}
{'loss': 0.2789, 'learning_rate': 1.6185819070904646e-05, 'epoch': 0.86}
{'loss': 0.3058, 'learning_rate': 1.6161369193154035e-05, 'epoch': 0.87}
{'loss': 0.2297, 'learning_rate': 1.6136919315403424e-05, 'epoch': 0.87}
{'loss': 0.2756, 'learning_rate': 1.6112469437652814e-05, 'epoch': 0.87}
{'loss': 0.3923, 'learning_rate': 1.6088019559902203e-05, 'epoch': 0.88}
{'loss': 0.3501, 'learning_rate': 1.606356968215159e-05, 'epoch': 0.88}
{'loss': 0.2974, 'learning_rate': 1.603911980440098e-05, 'epoch': 0.89}
{'loss': 0.2668, 'learning_rate': 1.6014669926650368e-05, 'epoch': 0.89}
{'loss': 0.3055, 'learning_rate': 1.5990220048899757e-05, 'epoch': 0.9}
{'loss': 0.3209, 'learning_rate': 1.5965770171149146e-05, 'epoch': 0.9}
{'loss': 0.3035, 'learning_rate': 1.5941320293398536e-05, 'epoch': 0.91}
{'loss': 0.216, 'learning_rate': 1.5916870415647922e-05, 'epoch': 0.91}
{'loss': 0.2817, 'learning_rate': 1.5892420537897314e-05, 'epoch': 0.92}
{'loss': 0.3161, 'learning_rate': 1.58679706601467e-05, 'epoch': 0.92}
{'loss': 0.3442, 'learning_rate': 1.584352078239609e-05, 'epoch': 0.93}
{'loss': 0.3399, 'learning_rate': 1.5819070904645476e-05, 'epoch': 0.93}
{'loss': 0.1666, 'learning_rate': 1.579462102689487e-05, 'epoch': 0.94}
{'loss': 0.2184, 'learning_rate': 1.5770171149144254e-05, 'epoch': 0.94}
{'loss': 0.2483, 'learning_rate': 1.5745721271393644e-05, 'epoch': 0.95}
{'loss': 0.2405, 'learning_rate': 1.5721271393643033e-05, 'epoch': 0.95}
{'loss': 0.2577, 'learning_rate': 1.5696821515892422e-05, 'epoch': 0.96}
{'loss': 0.2968, 'learning_rate': 1.567237163814181e-05, 'epoch': 0.96}
{'loss': 0.2221, 'learning_rate': 1.56479217603912e-05, 'epoch': 0.96}
{'loss': 0.3301, 'learning_rate': 1.5623471882640587e-05, 'epoch': 0.97}
{'loss': 0.4016, 'learning_rate': 1.5599022004889977e-05, 'epoch': 0.97}
{'loss': 0.3008, 'learning_rate': 1.5574572127139366e-05, 'epoch': 0.98}
{'loss': 0.2795, 'learning_rate': 1.5550122249388755e-05, 'epoch': 0.98}
{'loss': 0.3081, 'learning_rate': 1.5525672371638145e-05, 'epoch': 0.99}
{'loss': 0.3029, 'learning_rate': 1.550122249388753e-05, 'epoch': 0.99}
{'loss': 0.239, 'learning_rate': 1.547677261613692e-05, 'epoch': 1.0}
[2024-11-30 16:29:37,123] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[INFO|tokenization_utils_base.py:2432] 2024-11-30 16:29:55,485 >> tokenizer config file saved in /scratch-shared/ir2-less/out/llama2-13b-less-p0.05-lora-seed4/tmp-checkpoint-211/tokenizer_config.json
[INFO|tokenization_utils_base.py:2441] 2024-11-30 16:29:55,485 >> Special tokens file saved in /scratch-shared/ir2-less/out/llama2-13b-less-p0.05-lora-seed4/tmp-checkpoint-211/special_tokens_map.json
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/gpfs/home1/scur2847/ir2-less-data/less/train/train.py", line 192, in <module>
    main()
  File "/gpfs/home1/scur2847/ir2-less-data/less/train/train.py", line 171, in main
    train_result = trainer.train()
                   ^^^^^^^^^^^^^^^
  File "/home/scur2847/.local/lib/python3.11/site-packages/transformers/trainer.py", line 1537, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/scur2847/.local/lib/python3.11/site-packages/transformers/trainer.py", line 1929, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)
  File "/home/scur2847/.local/lib/python3.11/site-packages/transformers/trainer.py", line 2279, in _maybe_log_save_evaluate
    self._save_checkpoint(model, trial, metrics=metrics)
  File "/home/scur2847/.local/lib/python3.11/site-packages/transformers/trainer.py", line 2395, in _save_checkpoint
    os.rename(staging_output_dir, output_dir)
FileExistsError: [Errno 17] File exists: '/scratch-shared/ir2-less/out/llama2-13b-less-p0.05-lora-seed4/tmp-checkpoint-211' -> '/scratch-shared/ir2-less/out/llama2-13b-less-p0.05-lora-seed4/checkpoint-211'
