[2024-11-28 18:50:59,180] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Loading tasks: 0it [00:00, ?it/s]Loading tasks: 0it [00:00, ?it/s]
Loading prompts:   0%|          | 0/27 [00:00<?, ?it/s]Loading prompts: 100%|██████████| 27/27 [00:00<00:00, 12458.33it/s]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/gpfs/home1/scur2847/ir2-less-data/evaluation/eval/bbh/run_eval.py", line 333, in <module>
    main(args)
  File "/gpfs/home1/scur2847/ir2-less-data/evaluation/eval/bbh/run_eval.py", line 87, in main
    assert set(all_tasks.keys()) == set(all_prompts.keys(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError: task names in task data and task prompts are not the same.
set() {'date_understanding', 'ruin_names', 'dyck_languages', 'navigate', 'multistep_arithmetic_two', 'temporal_sequences', 'tracking_shuffled_objects_three_objects', 'disambiguation_qa', 'movie_recommendation', 'snarks', 'tracking_shuffled_objects_seven_objects', 'causal_judgement', 'tracking_shuffled_objects_five_objects', 'logical_deduction_five_objects', 'word_sorting', 'penguins_in_a_table', 'logical_deduction_seven_objects', 'object_counting', 'reasoning_about_colored_objects', 'formal_fallacies', 'sports_understanding', 'geometric_shapes', 'logical_deduction_three_objects', 'web_of_lies', 'hyperbaton', 'salient_translation_error_detection', 'boolean_expressions'}

JOB STATISTICS
==============
Job ID: 8813288
Cluster: snellius
User/Group: scur2847/scur2847
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 16
CPU Utilized: 00:00:11
CPU Efficiency: 2.86% of 00:06:24 core-walltime
Job Wall-clock time: 00:00:24
Memory Utilized: 2.27 MB
Memory Efficiency: 0.00% of 180.00 GB
